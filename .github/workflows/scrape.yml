name: LTK Scraper

on:
  # Manual trigger
  workflow_dispatch:
    inputs:
      category:
        description: 'Category to scrape (or "all" for all categories)'
        required: false
        default: 'ltkfindsunder50'
        type: choice
        options:
          - ltkfindsunder50
          - ltkfindsunder100
          - ltksalealert
          - ltkbeauty
          - ltkhome
          - ltkfit
          - ltkworkwear
          - all

  # Scheduled runs (daily at 6 AM UTC)
  schedule:
    - cron: '0 6 * * *'

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Install Chromium for Puppeteer
        run: npx puppeteer browsers install chrome

      - name: Run scraper
        run: |
          if [ "${{ github.event.inputs.category }}" = "all" ] || [ -z "${{ github.event.inputs.category }}" ]; then
            echo "Scraping all categories..."
            npm run scrape:all
          else
            echo "Scraping category: ${{ github.event.inputs.category }}"
            npm run scrape:api -- --category ${{ github.event.inputs.category }}
          fi
        env:
          PUPPETEER_EXECUTABLE_PATH: /usr/bin/google-chrome-stable

      - name: Upload scraped data as artifact
        uses: actions/upload-artifact@v4
        with:
          name: ltk-scraped-data-${{ github.run_id }}
          path: data/scraped/*.json
          retention-days: 30

      - name: Upload to GCS (if configured)
        if: env.GCP_SA_KEY != ''
        run: npm run upload:gcs
        env:
          GCP_SA_KEY: ${{ secrets.GCP_SA_KEY }}
          GCP_PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}
          GCS_BUCKET: ${{ secrets.GCS_BUCKET }}

  notify:
    runs-on: ubuntu-latest
    needs: scrape
    if: failure()

    steps:
      - name: Notify on failure
        run: |
          echo "Scrape job failed! Check the logs for details."
          # Add Slack/Discord webhook notification here if needed
